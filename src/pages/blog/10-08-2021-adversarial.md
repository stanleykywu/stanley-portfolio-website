## 10.08.2021 The Potential Threat Of Adversarial Machine Learning In The Software Industry

Machine learning has quickly become a popular “buzzword” for companies seeking to update their technology stacks with the state of the art. Yet unlike more traditional technology frameworks such as web development, and mobile app development … etc., that are mostly deterministic and easily tested, machine learning throws a wrench into what’s considered traditional software development. Machine learning is a flexible algorithm that learns and identifies patterns in datasets to automate decision making. Examples of machine learning applications include computer vision and natural language processing. Tesla’s autopilot feature uses computer vision, or CV for short, to analyze images of the road and tell the vehicle what to do, and there are many online chatbots that use natural language processing, or NLP, to respond to text queries. Flexibility is the greatest strength of machine learning, as well as its most dangerous feature. These models are prone to outside influence, which can cause harm when dealing with sensitive information. However this problem has not slipped under the noses of machine learning researchers. Between 2017 and 2019, there have been over 200 written papers on the potential pitfalls and failures of machine learning when attacked by an adversary (Marshall et al., 2018). Since academic research on attacking machine learning models, or adversarial machine learning, continues to be a focal point of machine learning and security research, the threat it poses to software development is also ever evolving. Continue reading <a href="https://stanleykywu.github.io/ds-blog/2021/10/08/The-Potential-Threat-of-Adversarial-Machine-Learning-in-the-Software-Industry.html" style="color: #4db5ff;">here</a>!
